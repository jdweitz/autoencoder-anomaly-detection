{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastjet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import vector\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "JET_ALGO = fastjet.antikt_algorithm\n",
    "R = 1.0\n",
    "MIN_JET_PT = 30.0\n",
    "MAX_JETS = 2\n",
    "MAX_PARTICLES_PER_JET = 10\n",
    "\n",
    "chunks = [\n",
    "    (\"events_anomalydetection_v2.h5\", 0, 100_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 100_000, 200_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 200_000, 300_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 300_000, 400_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 400_000, 500_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 500_000, 600_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 600_000, 700_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 700_000, 800_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 800_000, 900_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 900_000, 1_000_000),  # background\n",
    "    (\"events_anomalydetection_v2.h5\", 1_000_000, 1_100_000),  # two prong signal\n",
    "    (\"events_anomalydetection_Z_XY_qqq.h5\", 0, 100_000),  # three prong signal\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper function to make awkward arrays of fixed size\n",
    "def fill_pad(ak_array, max_n=10, axis=-1, pad=0, clip=True):\n",
    "    return ak.fill_none(\n",
    "        ak.pad_none(ak_array, max_n, clip=clip, axis=axis), pad, axis=axis\n",
    "    )\n",
    "\n",
    "\n",
    "# given a dataframe, get formatted datasets\n",
    "def get_datasets(df, filename):\n",
    "    # reshape to 700 particles with 3 features (px, py, pz)\n",
    "    p = df.values[:, :-1].reshape(len(df), 700, 3)\n",
    "\n",
    "    # get labels\n",
    "    labels = df.values[:, -1]\n",
    "\n",
    "    # use label=0 for background, label=1 for two prong signal, label=2 for three prong signal\n",
    "    if \"events_anomalydetection_Z_XY_qqq\" in filename:\n",
    "        labels += 1.0\n",
    "\n",
    "    # split into momentum components\n",
    "    pt = p[..., 0]\n",
    "    eta = p[..., 1]\n",
    "    phi = p[..., 2]\n",
    "    # mask out zero-padded particles\n",
    "    mask = pt > 0\n",
    "\n",
    "    # convert to awkard arrays\n",
    "    ak_pt = ak.from_iter([a[m] for a, m in zip(pt, mask)])\n",
    "    ak_eta = ak.from_iter([a[m] for a, m in zip(eta, mask)])\n",
    "    ak_phi = ak.from_iter([a[m] for a, m in zip(phi, mask)])\n",
    "\n",
    "    # use vector library to make a high-level array of 4-momenta\n",
    "    # assuming massless particles\n",
    "    particles = ak.zip(\n",
    "        {\n",
    "            \"px\": ak_pt * np.cos(ak_phi),\n",
    "            \"py\": ak_pt * np.sin(ak_phi),\n",
    "            \"pz\": ak_pt * np.sinh(ak_eta),\n",
    "            \"E\": ak_pt * np.cosh(ak_eta),\n",
    "        },\n",
    "        with_name=\"MomentumArray4D\",\n",
    "    )\n",
    "\n",
    "    # define jet clustering algorithm\n",
    "    jetdef = fastjet.JetDefinition(JET_ALGO, R)\n",
    "\n",
    "    # perform jet clustering; this can take a while (~2 minutes for 100k events on my MacBook)\n",
    "    cluster = fastjet.ClusterSequence(particles, jetdef)\n",
    "\n",
    "    # retrieve jets\n",
    "    jets = cluster.inclusive_jets(min_pt=MIN_JET_PT)\n",
    "\n",
    "    # sort jets by pt\n",
    "    sorted_by_jet_pt = ak.argsort(jets.pt, ascending=False, axis=-1)\n",
    "    jets = jets[sorted_by_jet_pt]\n",
    "\n",
    "    # similarly sort constituents of jets by the jet pt\n",
    "    constituents = cluster.constituents(min_pt=MIN_JET_PT)\n",
    "    constituents = constituents[sorted_by_jet_pt]\n",
    "\n",
    "    print(constituents)\n",
    "    # within each jet, sort consituents by pt\n",
    "    sorted_by_constituent_pt = ak.argsort(\n",
    "        np.sqrt(constituents.px**2 + constituents.py**2), ascending=False, axis=-1\n",
    "    )\n",
    "    print(sorted_by_constituent_pt)\n",
    "    constituents = constituents[sorted_by_constituent_pt]\n",
    "    print(constituents)\n",
    "    # zero-pad constituents to fixed size (MAX_JETS jets per event, MAX_PARTICLES_PER_JET particles per jet)\n",
    "    constituents_padded_px = fill_pad(\n",
    "        fill_pad(constituents.px, max_n=MAX_JETS, axis=-2, pad=[0]),\n",
    "        max_n=MAX_PARTICLES_PER_JET,\n",
    "        axis=-1,\n",
    "        pad=0,\n",
    "    ).to_numpy()\n",
    "    constituents_padded_py = fill_pad(\n",
    "        fill_pad(constituents.py, max_n=MAX_JETS, axis=-2, pad=[0]),\n",
    "        max_n=MAX_PARTICLES_PER_JET,\n",
    "        axis=-1,\n",
    "        pad=0,\n",
    "    ).to_numpy()\n",
    "    constituents_padded_pz = fill_pad(\n",
    "        fill_pad(constituents.pz, max_n=MAX_JETS, axis=-2, pad=[0]),\n",
    "        max_n=MAX_PARTICLES_PER_JET,\n",
    "        axis=-1,\n",
    "        pad=0,\n",
    "    ).to_numpy()\n",
    "    constituents_pt = np.sqrt(constituents.px**2 + constituents.py**2)\n",
    "    constituents_padded_pt = fill_pad(\n",
    "        fill_pad(constituents_pt, max_n=MAX_JETS, axis=-2, pad=[0]),\n",
    "        max_n=MAX_PARTICLES_PER_JET,\n",
    "        axis=-1,\n",
    "        pad=0,\n",
    "    ).to_numpy()\n",
    "    constituents_padded_eta = fill_pad(\n",
    "        fill_pad(\n",
    "            np.arcsinh(constituents.pz / constituents_pt),\n",
    "            max_n=MAX_JETS,\n",
    "            axis=-2,\n",
    "            pad=[0],\n",
    "        ),\n",
    "        max_n=MAX_PARTICLES_PER_JET,\n",
    "        axis=-1,\n",
    "        pad=0,\n",
    "    ).to_numpy()\n",
    "    constituents_padded_phi = fill_pad(\n",
    "        fill_pad(\n",
    "            np.arctan2(constituents.py, constituents.px),\n",
    "            max_n=MAX_JETS,\n",
    "            axis=-2,\n",
    "            pad=[0],\n",
    "        ),\n",
    "        max_n=MAX_PARTICLES_PER_JET,\n",
    "        axis=-1,\n",
    "        pad=0,\n",
    "    ).to_numpy()\n",
    "\n",
    "    # stack constituent px, py, pz, pt, eta, phi into a single array\n",
    "    constituents_padded = np.stack(\n",
    "        [\n",
    "            constituents_padded_px,\n",
    "            constituents_padded_py,\n",
    "            constituents_padded_pz,\n",
    "            constituents_padded_pt,\n",
    "            constituents_padded_eta,\n",
    "            constituents_padded_phi,\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    jets_padded_px = fill_pad(jets.px, max_n=MAX_JETS, axis=-1, pad=0).to_numpy()\n",
    "    jets_padded_py = fill_pad(jets.py, max_n=MAX_JETS, axis=-1, pad=0).to_numpy()\n",
    "    jets_padded_pz = fill_pad(jets.pz, max_n=MAX_JETS, axis=-1, pad=0).to_numpy()\n",
    "\n",
    "    jets_padded_pt = fill_pad(jets.pt, max_n=MAX_JETS, axis=-1, pad=0).to_numpy()\n",
    "    jets_padded_eta = fill_pad(jets.eta, max_n=MAX_JETS, axis=-1, pad=0).to_numpy()\n",
    "    jets_padded_phi = fill_pad(jets.phi, max_n=MAX_JETS, axis=-1, pad=0).to_numpy()\n",
    "\n",
    "    jets_padded = np.stack(\n",
    "        [\n",
    "            jets_padded_px,\n",
    "            jets_padded_py,\n",
    "            jets_padded_pz,\n",
    "            jets_padded_pt,\n",
    "            jets_padded_eta,\n",
    "            jets_padded_phi,\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "    return constituents_padded, labels, jets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_constituents_padded = []\n",
    "all_labels = []\n",
    "all_jets_padded = []\n",
    "\n",
    "for i, (filename, start, stop) in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i+1}/{len(chunks)}: {filename}, {start}-{stop}\")\n",
    "    df = pd.read_hdf(filename, start=start, stop=stop)\n",
    "    constituents_padded, labels, jets_padded = get_datasets(df, filename)\n",
    "\n",
    "    print(f\"constituents_padded={constituents_padded[0]}\")\n",
    "    print(f\"labels={labels[0]}\")\n",
    "    print(f\"jets_padded={jets_padded[0]}\")\n",
    "    all_constituents_padded.append(constituents_padded)\n",
    "    all_labels.append(labels)\n",
    "    all_jets_padded.append(jets_padded)\n",
    "\n",
    "constituents_padded = np.concatenate(all_constituents_padded)\n",
    "labels = np.concatenate(all_labels)\n",
    "jets_padded = np.concatenate(all_jets_padded)\n",
    "\n",
    "# write out hdf5 file\n",
    "with h5py.File(\"constituents_rd_dataset.h5\", \"w\") as output:\n",
    "    output.create_dataset(\"constituents_padded\", data=constituents_padded)\n",
    "    output.create_dataset(\"labels\", data=labels)\n",
    "    output.create_dataset(\"jets_padded\", data=jets_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with h5py.File(\"constituents_rd_dataset.h5\", \"r\") as input:\n",
    "    print(input[\"constituents_padded\"])\n",
    "    print(input[\"labels\"])\n",
    "    print(input[\"jets_padded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastjet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
